## MySQL(10.1~10.7)

> MySQL执行过程（server层+引擎层）

1. 连接器判断用户身份以及用户权限
2. 查询缓存，缓存命中直接返回（5.6版本默认关闭，8.0版本删除）
3. 分析器针对SQL语句进行分析，包括预处理和解析过程
4. 优化器针对SQL进行优化，并针对全表扫描以及能使用的索引进行计算，选择成本最佳的执行方案（I/O成本+CPU成本最小）
5. 执行器调用存储引擎的api执行SQL

+ 更新操作执行过程（innodb）
  + 加载数据所在磁盘页：找到符合条件的数据所在磁盘页并加载到buffer pool中
  + 追加undo log：顺序将旧值写入undo log磁盘文件
  + 更新buffer pool：将buffer pool中的数据进行更新
  + 写redo log缓存：将redo log写入redo buffer
  + 写bin log缓存：将bin log写入bin buffer
  + 持久化redo log到磁盘：将redo buffer中的数据顺序写入redo磁盘文件，标记为prepare阶段
  + 持久化bin log到磁盘：将bin buffer文件顺序写入磁盘
  + 标记：写入commit标记至redo log磁盘文件中，代表update事务已经提交且redo log和bin log一致（两阶段提交结束）
  + 刷盘：单独有线程将buffer pool中的数据随机IO刷至磁盘

> MySQL的数据结构

+ File Header：页的通用信息
+ Page Header：数据页专有的信息
+ Infimum & Supremum Records：记录当前页的最大、最小记录
+ User Records：实际存储的行记录的内容
+ Free Space：页中尚未使用的空间
+ Page Directory：页中的某些记录的相对位置（MySQL新增数据时会创建对应的Slot，一个Slot包含多条记录，借助Slot可实现二分查找记录）
+ File Tailer：校验页是否完整

> redo日志日志序列号（Log Sequeue Number）

+  lsn：随着redo日志的不断增加，为了记录写入的redo日志的量设计了一个日志序列号的全局变量，初始值为8704，lsn越小，说明日志越早产生

+ flushed _to_disk_lsn：标记当前logbuffer中已经有哪些日志被刷新到磁盘中（redo日志先写到logbuffer中，之后才会刷新到磁盘）

+ checkpoint_lsn：标记当前系统中可以被覆盖的redo日志总量，初始值为8704（redo日志文件组容量有限，会循环使用redo日志文件，checkpoint_lsn之前的redo日志可以额比覆盖掉）

  ~~~txt
  checkpoint_lsn之前的日志对应的脏页已经被刷新到磁盘，所以checkpoint_lsn之前的日志文件中的内容可以被覆盖
  checkpoint_lsn~flushed_to_disk_lsn之间的日志已经从logbuffer刷新到日志文件中，但是脏页还不能确定有没有被刷盘
  flushed_to_disk_lsn~lsn之间的redo日志还留在log bugger中，redo日志没有刷新到文件，并且脏页没有被刷新到磁盘
  ~~~

> 恢复时如何知道某个redo日志对应的脏页是都在系统崩溃时已经刷盘

​	File Header中包含FIL_PAGE_LSN的属性，该属性记载了最近一次修改页面时对应的lsn值，如果在做了某次checkpoint后有脏页刷盘，那么该页对应的FIL_PAGE_LSN代表的lsn值肯定大于checkpoint_lsn值，凡是符合这种情况的页面就不需要重复执行lsn值小于FIL_PAGE_LSN的redo日志。

> Buffer Pool

​	数据库的一个内存组件，里面缓存了磁盘上的真实数据，对数据库的增删改查操作都是对buffer pool中的数据进行操作

+ Free Page：未被使用的页，位于Free链表
+ Clean Page：已被使用的页，但页内数据没有被修改，位于LRU链表
+ Dirty Page：已被使用且页内数据被修改，页内数据与磁盘数据不一致（脏页数据被写入磁盘后变为Clean Page），位于LRU链表和Flush链表
+ Free List：记录空闲页面（每次加载数据到内存中，会判断Free链表页面是否够用，不够则flush LRU链表和Flush链表释放空闲页，够则从Free链表中删除并添加到LRU链表中）
+ LRU List：记录在使用中的页并选择将哪些数据进行淘汰（分为Young链表/热数据区和Old链表/冷数据区，新读取的页添加在Old链表的头部，频繁访问的页会往Young链表的头部移动，最终Old链表尾部的页面将被淘汰）
+ Flush List：记录脏页数据（由后台线程Page Cleaner从尾部开始扫描执行flush操作）

> 脏页刷新条件

+ redo日志快满的时候（redo日志对应的脏数据还没有被写入磁盘就被覆盖掉的话，程序崩溃时无法进行数据恢复）
+ 为了保证MySQL中的空闲页面的数量（从LRU尾部淘汰一部分页面作为空闲页时，如果是脏页就需要先将页面flush到磁盘）
+ 脏页太多（脏页数量到达一定比例时默认75%会强制进行刷页保证系统有足够的Free Page）
+ MySQL正常关闭时也会把内存中的脏页全部刷新到磁盘

> InnoDB锁类型

+ 锁的属性分类：共享锁/读锁/S锁、排他锁/写锁/X锁
  + 共享锁：支持并发的读取数据，读取数据时不支持修改，避免出现重复读问题
  + 排他锁：在数据修改时候不允许其他人同时修改，也不允许其他人读取，避免了出现脏数据和脏读问题。
+ 锁的粒度分类：表级锁、行级锁
  + 表锁：SQL语句没有使用索引时会进行全表扫描，使用表锁锁定整张表
  + 行锁：锁住的是表的某一行或者多行记录（记录锁、间隙锁、临键锁）
    + 记录锁：锁住表中的某一条记录（精准条件命中且命中的条件字段时唯一索引）
    + 间隙锁：Gap锁，锁住表记录的某一段左开右开区间（插入意向锁也是间隙锁，在insert操作中产生，不阻止任何锁，和Gap锁冲突）
    + 临键锁：Next-key锁，记录锁+间隙锁（左开右闭区间）
+ 锁的状态分类：意向共享锁、意向排他锁
  + 属于表级锁，用于记录当前表是否已经有记录被添加上共享锁或排他锁，意向锁之间不冲突

> InnoDB和MyiSAM的存储格式

+ InnoDB：.frm文件（表结构定义信息） + .ibd文件（索引+数据）
+ MyiSAM：.frm文件（表结构定义信息） + .myd文件（数据） + .myi文件（索引）

> InnoDB和MyiSAM区别

|     Innodb     |                            MyiSAM                            |
| :------------: | :----------------------------------------------------------: |
|    支持事务    |                          不支持事务                          |
| 支持行锁、表锁 | 只支持表锁，读锁写锁互斥且写优先级高，并发查询、修改时查询会长时间阻塞 |
|    支持外键    |                          不支持外键                          |
| 不支持全文索引 | 支持全文索引，对char、varchar和text中的每个词（停用词除外）建立倒排序索引 |

> MyiSAM查询为什么比InnoDB快

+ InnoDB支持事务，存在mvcc比较的过程
+ InnoDB走二级索引查询时存在回表
+ InnoDB支持行锁，检查锁时要检查表锁和行锁

## Redis(10.8~10.16)



## Java(10.17~10.23)

> synchronized底层实现

+ 同步代码块：代码块被 **monitorenter** 和 **monitorexit**指令环绕
+ 同步方法：方法会有一个叫作 **ACC_SYNCHRONIZED** 的 **flag** 修饰符，有**ACC_SYNCHRONIZED** 标志时需要先获取monitor锁，然后才能开始执行方法，方法执行后释放monitor锁

> Mark word存储结构（64位虚拟机）

![在这里插入图片描述](https://img-blog.csdnimg.cn/824637f9e03d49409a307e9266efed00.png)

> synchronized锁升级

+ 无锁：【0】【01】无任何线程持有锁
+ 偏向锁：【1】【01】当一个线程访问同步块并获取锁时，会在对象头和栈帧中记录存储锁偏向的线程ID，以后该线程在进入同步块时先判断对象头的Mark Word里是否存储着指向当前线程的偏向锁，如果存在就直接获取锁
+ 轻量级锁：【00】当其他线程尝试竞争偏向锁时，锁升级为轻量级锁。线程尝试获取锁之前会在栈中建立一个`Lock Record`用于存储锁对象目前的Mark Word的拷贝，通过CAS 操作尝试将锁对象的 Mark Word 更新为指向`Lock Record`的指针，成功则表示获取到锁并将标志位设置为00，失败则表示Mark Word已经被替换成其他线程的锁记录，然后通过自旋尝试获取锁
+ 重量级锁：【10】自旋到达一定次数（默认10次）后仍未获取到锁则升级为重量级锁

## Spring(10.24~10.30)

> Spring的三级缓存（只有存在循环引用状态的bean才会被保存在二级缓存中）

+ A对象实例化后，将A对象包装成ObjectFactory方法放入三级缓存，填充B对象
+ 缓存中没有B对象，创建B对象并实例化后，将B对象包装成ObjectFactory方法放入三级缓存，填充A对象
+ 三级缓存中存在A对象，获取A对象的ObjectFactory生成早期曝光A对象（如果需要代理就是代理对象，不需要则为原对象），并删除三级缓存A对象将早期曝光A对象放入二级缓存，然后完成B对象的初始化，删除三级缓存B对象并放入一级缓存
+ B对象初始化后，继续给A对象填充B对象，待A对象初始化完成后，将A对象放入一级缓存并删除二级缓存



## Kafka+RocketMQ(10.31~11.6)

> Kafka高性能的原因：顺序读写+零拷贝（mmap+sendfile）

+ partition顺序读写，不需要随机寻址
+ producer生产的数据持久化到broker，采用mmap（Memory Mapped Files，在虚拟内存地址空间中分配地址空间，创建和物理内存的映射关系，对物理内存的操作会被同步到硬盘）文件映射，实现快速写入
  + 但不可靠，写入到mmap中的数据并未真正写入磁盘，于是Kafka提供参数控制是否主动刷盘：如果写入mmap后立即flush再返回producer叫同步刷盘，如果写入mmap后立即返回producer叫异步刷盘
+ customer从broker读取数据采用sendfile，将磁盘文件读到操作系统内核缓冲区后，直接转到socket buffer进行网络发送

> Kafka消息处理流程

+ 写流程

  + 生产者从zk找到当前partition的leader所属的brokerId，再根据brokerId找到对应的broker
  + broker上的leader将消息写入本地log中，并同步给ISR里面的follower
  + ISR里的follower同步数据后返回给leader ACK，leader确认数据同步完成后返回给生产者ACK

+ 读流程

  + 消费者从zk找到partition的leader所在的broker以及offest

  + 从leader的offest开始往后顺序拉取数据

  + 提交offest

    + 自动提交：每隔5秒（可配置）会将拉取到的最大消息偏移量提交一次，无法精确管理offest

    + 手动提交：由开发人员自行控制提交offest时机，分为同步提交和异步提交，可采用同步+异步组合提交

      ~~~java
      try {
          while (true) {
              // 消费者poll并且执行一些操作
              // ...
      
              // 异步提交，也可使用有回调函数的异步提交。较同步提交速度更快。
              consumer.commitAsync();
          }
      } catch (Exception e) {
          logger.error("Unexpected error" , e);
      } finally {
          try {
              // 同步提交，来做位移提交最后的保证。
              consumer.commitSync();
          } finally {
              consumer.close();
          }
      }
      ~~~

> zookeeper在kafka中的作用（低版本）

+ zk只管理broker和consumer（均在zk上存了具体数据），producer直接连接broker，只在zk上注册监听，监听broker、topic信息（在zk注册数据才算被管理，只注册监听不算被zk管理）
  + broker使用zk来注册broker和topic信息，以及监控partition leader存活性
  + consumer使用zk来注册consumer信息，包括消费的partition列表、消费者的offest，同时也监听broker列表（和partition leader建立socket连接并获取消息）
  + producer和broker集群建立tcp连接，获取元数据信息，其中包含topic下每个partition leader信息，建立socket连接并发送消息（每个producer通常会和一个broker建立两个tcp连接，一个用于更新元数据，一个用于发送消息）

> kafka中的group coordinator（群组协调者）

+ 低版本的kafka消费者依赖zk完成offest保存以及rebalance，从0.9.0开始使用新的bootstrap。servers替代zookeeper.connect，减少对zk依赖
+ 使用bootstrap.servers替代之前版本的zookeeper.connect包括
  + 在server端增加了GroupCoordinator这个角色
  + 将topic的offest信息由在zk上存储改为存储到一个特殊的topic中
+ Coordinator一般指运行在broker上的group coordinator，用于管理consumer group中的各个成员，每个kafka server都有一个group coordinator实例，管理多个消费者组（所有消费者群组的子集），主要用于offest位移管理和消费者rebalancce

> 消费者群组如何选择group coordinator（群组协调者）

+ 确定由_consumer_offests位移主题的哪个分区来保存该消费者群组的数据

~~~java
partitionId=Math.abs(groupId.hashCode() % offsetsTopicPartitionCount)
~~~

+ 找出该分区所在leader副本所在的broker，该broker即为group coordinator

> consumer和coordinator是如何交互的

+ 消费者发送joinGroup请求到协调者
+ 协调者从消费者群组选择一个消费者作为leader（第一个加入的消费者）
+ 协调者将要消费的topic分区情况发送给leader
+ leader负责制定消费方案并发送给协调者
+ 协调者把消费方案下发给各个消费者
+ 消费者从指定分区的leader broker消费数据

> 什么时候会发生分区再均衡

+ 有新的消费者加入消费者群组
+ 有消费者宕机下线（不一定真正下线，例如遇到长时间的GC、网络延迟导致消费者长时间未向group coordinator发送心跳）
+ 有消费者主动退出消费者群组
+ 消费者群组对应的group coordinator节点发生变化
+ 消费者群组所订阅的任一主题或主题的分区数量发生变化

> kafka中的ISR、OSR、AR

+ 与leader副本保持一定的同步程度的副本集合叫ISR（速率和leader相差低于10秒，包括leader）
+ 与leader副本滞后太多的副本集合叫OSR（速率和leader相差大于10秒）
+ 分区中所有的副本叫AR

## Zookeeper+Nacos(11.7~11.13)

> Nacos和Zookeeper区别

|                    |             Zookeeper              |                            Nacos                             |
| :----------------: | :--------------------------------: | :----------------------------------------------------------: |
|        CAP         |               支持CP               | 支持AP和CP（AP模式服务以临时实例注册，CP模式下服务以永久实例注册） |
| 配置中心：存储位置 |        使用自身树状节点存储        |                        采用MySQL存储                         |
| 配置中心：数据更新 | 采用过半机制保持各个节点数据一致性 |   更新数据库，异步广播给其他节点更新本地缓存，后台线程重试   |
|      注册中心      | 信息存储在节点，过半机制保持一致性 | 非持久存储在内存，节点hash分片；持久化使用raft选举master存储在leader |
|      健康检查      |        客户端发送tcp心跳包         | 客户端主动上报（http、rpc）和服务端主动下探（http、tcp、mysql） |
